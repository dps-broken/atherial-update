# robots.txt for Aetherial Code
# Optimized for SEO, crawl efficiency & content protection

# Global Rules
User-agent: *
Allow: /

# Disallow non-essential or duplicate content
Disallow: /assets/          # Static assets (CSS, JS, icons handled via CDN)
Disallow: /admin/           # Admin panel (restricted access)
Disallow: /private/         # Confidential resources
Disallow: /tmp/             # Temporary files or logs
Disallow: /cgi-bin/         # Legacy server scripts
Disallow: /*?*              # Block URL parameters to avoid duplicate content
Disallow: /*.php$           # Prevent direct PHP file indexing (if any)

# Sitemap (critical for SEO indexing)
Sitemap: https://www.aetherialcode.com/sitemap.xml

# Crawl-delay (optional, use only if server load issues occur)
# Crawl-delay: 10

# Major Search Engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

# Block unwanted or low-value crawlers
User-agent: Baiduspider
Disallow: /                 # No Chinese audience, block crawl

User-agent: Yandex
Disallow: /                 # Block Russian bot if not targeting that region

User-agent: AhrefsBot
Disallow: /                 # Block aggressive SEO crawlers

User-agent: SemrushBot
Disallow: /                 # Block if you donâ€™t want competitors analyzing

User-agent: MJ12bot
Disallow: /                 # Block spammy crawler

# End of robots.txt
